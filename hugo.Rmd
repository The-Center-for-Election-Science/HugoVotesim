---
title: "hugo"
author: "Jameson Quinn"
date: "May 5, 2015"
output: ioslides_presentation
---

## R Markdown

This is an R Markdown presentation. You can turn it into an HTML slide show using R Studio. If you don't already know how to do this, Google is your friend.

## Bootstrapping

Say you want to know how likely something is, but you only have one set of data. With the data you have, the thing is either true or it isn't, but you know the probability isn't really 0% or 100%. Statisticians have a solution to this problem, called "bootstrapping": you put all the n data points you have in a hat, and draw n points out of the hat, but replacing each one as you draw it out. So you'll have n "new" points, which are really just your original points except that some appear twice and some are missing. Then you see if the thing is true for this new data set. Do that a bunch of times, and see how often the thing is true; that is an estimate of the probability it will be true in data sets "like" your actual data. There's lots of statistical theory about why bootstrapping is a reasonable thing to do, and also about how to make it even better.

## Hugo data

We have all the ballot data for the 1984 Hugos. We can use it, and bootstrapping, to answer various questions. For instance: how likely is it that SDV-LPE would give the same answer as the current system? How likely is it that one tiebreaker would give the same answer as another within SDV-LPE? How common are ties, anyway?

## "Conservative" simulations

In general, we're going to be bootstrapping only 100 ballots at a time. With fewer ballots, more hinges on each of the random draws we make, so "unusual" results (such as ties, etc) are going to be more common than they would be in real life. Very roughly speaking, if a typical Hugo real-life election has 1600 ballots, then it will be $\sqrt{16}=4$ times less likely to have unusual results. So if a system does well in our sims, it will probably do 4 times better in real life.

## Code. 

I haven't made any nice graphs, so from here on in, you have to read the code. Sorry.


```{r}

library(data.table)
library(ggplot2)
library(boot)
library(elasticnet)
library(plyr)
library(stringdist)

#the names of the categories.
cats = c("1 - novel", "2 - novella", "3 - novelette", "4 - short story", 
"5 - non-fiction book", "6 - dramatic presentation", "7 - pro editor", 
"8 - pro artist", "9 - semiprozine", "10 - fanzine", "11 - fan writer", 
"12 - fan artist", "13 -  Campbell Award (not a Hugo)") 

#Get the data
hugos = data.table(read.fwf("catsort.txt",widths = c(5,3,9,9,76-27,2,113-78,99),comment.char="", strip.white=T))
setnames(hugos,c("voter","cat","postdate","gotdate","title","numvotes","author","publisher"))
hugos[,title:=as.character(title)]

#Quick-and-dirty fuzzy string matching, so that the same work will count as the same despite minor typos. 
titles = c()
for (i in 1:dim(hugos)[1]) { #look at the titles one at a time
  title = hugos[i,title]
  
  #How far is the current title from each unique title we've seen so far?
  titdist = stringdist(titles, title, method="jw")
  
  #empty title strings could lead to "infinite" distance; set to 1, which is the maximum.
  if (all(!is.finite(titdist))) {
    titdist = rep(1,length(titdist))
  }
  if (hugos[i,cat] < 7) {
    cutoff = 0.13 #for works of fiction, a slightly looser matching
  } else {
    cutoff = 0.09 #for people's names, a slightly tighter matching. We don't want "Jason Smith" to match "James Smithson".
  }
  if (min(titdist) > cutoff) { #we've found a match - it's not a new title
    titles = c(titles,title) #add it to the list of titles we've seen so far
    titdist = c(titdist,0) #its distance from itself is 0
  } else if (min(titdist) > (cutoff / 2)) { #borderline case
    cat(hugos[i,cat],min(titdist),title,titles[which(titdist == min(titdist))[1]],"\n") #print it out, so whoever's watching this routine run will see the tough calls and can adjust the threshold and rerun if needed.
  }
  
  hugos[i,titindex:=  which(titdist == min(titdist))[1]] #Mark the ballot with the index of the matching title in the canonical list
  if (i %% 1000 == 0) { #mark progress
    print(i)
    print("....")
    }
}

#Print out the top 5 vote-getters in the "best novel" category
novels = hugos[cat==1]
titles[novels[,.N,by=titindex][order(-N)][1:5,titindex]] 

# How many works with n or more votes in each category?
for (i in 1:13) {cat("Category",cats[i],"- had",sum(count(hugos[cat==i,][,.N,by=titindex][,N])[-1:-3,2]),"works with 3 or more votes.\n")}

#a function to run SDV-LPE on one category worth of ballots
sdvlpe = function(ballots, allValid = T) {
  #count raw votes
  if (!("rawvotes" %in% names(ballots))) {
    ballots[,rawvotes:=.N,by=titindex]
  }
  
  #find plurality winners
  rawOrder = ballots[,.N,by=titindex][order(-N)]
  nwin = 5
  while (rawOrder[nwin,N] == rawOrder[nwin+1,N]) {
    nwin = nwin + 1
  }
  rawWinners = sort(rawOrder[1:nwin,titindex])
  
  #find SDVLPE winners
  if (allValid) {
    ballots[,valid:=T] #mark all votes as valid to start out with.
  }
  done=F
  #Mass elimination of no-hope candidates (for speed)
  ballots[valid==T,fvotes:=1/.N,by=voter]
  fvotes = ballots[,list(f=sum(fvotes),raw=rawvotes[1]),by=titindex][order(-f)]
  cutoff = fvotes[5,f]
  ballots[rawvotes < cutoff, valid:=F]
  
  ties = c()
  allFs = data.table()
  strange = F
  round = 0
  while (!done) {
    round = round + 1
    ballots[valid==T,fvotes:=1/.N,by=voter]
    fvotes = ballots[valid==T,list(f=sum(fvotes),raw=rawvotes[1],r =round),by=titindex][order(f)]
    allFs = rbind(allFs,fvotes)
    njoust = 2
    numcand = dim(fvotes)[1]
    while ((njoust < numcand) & (fvotes[njoust,f] == fvotes[njoust+1,f])) {
      njoust = njoust + 1
    }
    #print(fvotes)
    losers = fvotes[1:njoust]
    losers = losers[raw == min(losers[,raw]), titindex]
    #print(losers)
    if (length(losers) > 1) {
      losers = allFs[titindex %in% losers,sum(f * (2 ^ r)),by=titindex]
      losers = losers[V1 == min(losers[,V1]), titindex]
      if (length(losers) > 1) {
        ties = c(dim(fvotes)[1], ties)
      }
    }
    if ((dim(fvotes)[1] - length(losers)) < 5) {
      done = T
    } else {
      ballots[titindex %in% losers, valid:=F]
    }
  }
  
  winners = sort(fvotes[,titindex])
  return(list(rawtie=(nwin > 5),
              ties = ties,
              same = length(intersect(winners, rawWinners)),
              winners = winners,
              rawWinners = rawWinners
              ))
}

#a "statistic" function to pass to bootstrap. Calculates:
#1. How many winners are the same between SDV-LPE and status quo
#2. How many winners there are in SDV-LPE
#3. How many winners in status quo
#4. How many ties there are in SDV-LPE with fewer than 10 candidates remaining.
stat = function(ballots,orig) {
  sdv = sdvlpe(ballots)
  #if (length(sdv$rawWinners) > 5) {print(sdv$ties)}
  c(sdv$same,length(sdv$winners),length(sdv$rawWinners),sum(sdv$ties < 10))
}

#A separate bootstrap "statistic". Calculates how often a declined nomination would lead to a change in the other 4 winners if we rerun from scratch.
stableStat = function(ballots,orig) {
  sdv = sdvlpe(ballots)
  declined = sample(sdv$winners,1)
  sdv2 = sdvlpe(ballots[,valid:=(titindex != declined)],allValid=F)
  
  #if (length(sdv$rawWinners) > 5) {print(sdv$ties)}
  c(0,length(intersect(sdv$winners,sdv2$winners)))
}



for (i in 1:13) {
  onecat = hugos[cat == i]
  print(sdvlpe(onecat)$ties)
}

n = 600
for (i in 1:13) {
  onecat = hugos[cat == i]
  smaller = hugos[sample(1:dim(hugos)[1],n)]
  boots = boot(onecat,stat, R=100, 
               sim="parametric",
               mle = n
               ,ran.gen=function(d,n){d[sample(1:dim(d)[1],n   ,replace=T)]}#   )]}#,replace=T)]}#
               )
  print(colMeans(boots$t))
}
for (i in 1:13) {
  onecat = hugos[cat == i]
  smaller = hugos[sample(1:dim(hugos)[1],n)]
  boots = boot(onecat,stableStat, R=25, 
               sim="parametric",
               mle = n
               ,ran.gen=function(d,n){d[sample(1:dim(d)[1],n   ,replace=T)]}#   )]}#,replace=T)]}#
               )
  print(colMeans(boots$t))
}


```
